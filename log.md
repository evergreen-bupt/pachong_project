# 自动评估脚本开发记录——已完成的功能和需要测试的功能

## 以实现的功能

能够将找到正在进行的训练任务，并从中提取出一个模型

## 需要测试的功能（已经编写）

### 1.~~在一个训练任务中提取多个模型~~
### 1.从训练任务中提取最新模型

#### 需要测试的内容：

1. ~~在提取多个模型时，每两个模型选择一次，`for j in range(1, len(tr1_list), 2):`~~

   生成一个随机数，如果随机数大于0.5则选择第二个模型

   `k = j if random_number < 0.5 and j+1 <= len(tr1_list) else j+1`

   但此代码存在一个问题就是此数组可能是偶数，或者奇数，当`len(tr1_list)`为奇数的时候，最后会剩下一个，如`[(1,1),(1,1),(1,1),1]`当j为最后一个1的索引值时j+1不存在，因此此处需要测试测试。

2. 在导出模型之后，需要关闭模型导出页面和模型选取页面。需要测试是否正常关闭

   ```python
    s4 = self.browser.find_element(By.XPATH, '/html/body/div[2]/div/div[2]/div/div/div[1]/div/button/span/svg')       
    s4.click()
    time.sleep(1)    
    s4.click()
    #两个关闭按钮的Xpath是一样的，并且导出代码后模型选取页面是否自动关闭也没测试，如果自动关闭那只需要关闭一次，而不是两次。
   ```

#### 2. 不断翻页找到两个正在训练的任务

两个正在训练的任务可能在不同页，现如今实现的只是不停的翻页去寻找两个正在训练的任务，一直翻页直到找到为止，但是可能不存在训练任务或者训练任务只有一个，如何遍历所有任务后停止翻页，还没有写这个判断语句。

1. 需要测试一下翻页功能是否有用
2. 停止翻页的构思：判断当前是否是最后一页，通过查看页码List是否到底了。



## 11月6日更新
参考往届冠军的思路，现在只需要获取正在训练中任务的最新模型即可。因而只需要每隔一段时间自动提取模型即可。
### 已完成功能
实现了模型的自动评估功能，目前评估参数为：
双方均选择三种阵容进行对抗，\
评估轮数eval_num=5\
选取对手模型为baseline-2\
自动评估的时间间隔设置为10min\
后续可根据实际需要设置超参数方便更改
### TODO
#### 1.模型提取部分：
依据现有思路，我们需要维护两个并行的训练任务，需要同时保证对两个任务的模型提取工作，
并且需要不断地重复访问训练任务，并重复提交模型，这部分有待讨论与测试。
#### 2.模型评估指标的统计
根据评估结果，提取其中的信息，并维护出实时的模型对抗能力看板。
